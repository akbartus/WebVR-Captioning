# Image Captioning in Web VR
![Screenshot](assets/screenshot.jpg)

### **Description / Rationale**
This is small toy project, which shows the use of image captioning (machine learning task) at work. 


### **Goals**
The goals of the project are: 
* To demonstrate new type of reading experience. 
* To demonstrate advanced capabilities of web VR.
* To create accessible VR reading experience.


### **Structure**
The reading platform offers 4 modes for reading: 

**1. User-generated reading environment (Simple Mode)** 
In this mode users can use their own 360 photos or choose the default 3D model of a room or select one of five 3d environments and then upload a pdf file. The respective sound will be added automatically based on random selection (for now there are three types of sound: arts, tale and culture). In addition, there is a possibility to apply weather effects and toggle sound.

![Mode 1](assets/mode1.png)

### **Credits**
<p>3D model of the room (used in simple mode and interactive mode) was created by <b>Francesco
          Coldesina</b>, and taken from <a
          href="https://sketchfab.com/3d-models/big-room-0b5da073be88481091dbef7e55f1d180">Sketchfab.com</a></p>
### **Demo**
To see the application at work: [Demo application](https://www.vr-reader.com)
